{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e6e8302",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /home/aiton/anaconda3/lib/python3.11/site-packages (0.27.8)\n",
      "Requirement already satisfied: requests>=2.20 in /home/aiton/anaconda3/lib/python3.11/site-packages (from openai) (2.29.0)\n",
      "Requirement already satisfied: tqdm in /home/aiton/anaconda3/lib/python3.11/site-packages (from openai) (4.65.0)\n",
      "Requirement already satisfied: aiohttp in /home/aiton/anaconda3/lib/python3.11/site-packages (from openai) (3.8.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/aiton/anaconda3/lib/python3.11/site-packages (from requests>=2.20->openai) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/aiton/anaconda3/lib/python3.11/site-packages (from requests>=2.20->openai) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/aiton/anaconda3/lib/python3.11/site-packages (from requests>=2.20->openai) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/aiton/anaconda3/lib/python3.11/site-packages (from requests>=2.20->openai) (2023.5.7)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/aiton/anaconda3/lib/python3.11/site-packages (from aiohttp->openai) (22.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/aiton/anaconda3/lib/python3.11/site-packages (from aiohttp->openai) (6.0.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /home/aiton/anaconda3/lib/python3.11/site-packages (from aiohttp->openai) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/aiton/anaconda3/lib/python3.11/site-packages (from aiohttp->openai) (1.8.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/aiton/anaconda3/lib/python3.11/site-packages (from aiohttp->openai) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/aiton/anaconda3/lib/python3.11/site-packages (from aiohttp->openai) (1.2.0)\n",
      "Requirement already satisfied: langchain in /home/aiton/anaconda3/lib/python3.11/site-packages (0.0.252)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /home/aiton/anaconda3/lib/python3.11/site-packages (from langchain) (6.0)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /home/aiton/anaconda3/lib/python3.11/site-packages (from langchain) (1.4.39)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /home/aiton/anaconda3/lib/python3.11/site-packages (from langchain) (3.8.3)\n",
      "Requirement already satisfied: dataclasses-json<0.6.0,>=0.5.7 in /home/aiton/anaconda3/lib/python3.11/site-packages (from langchain) (0.5.14)\n",
      "Requirement already satisfied: langsmith<0.1.0,>=0.0.11 in /home/aiton/anaconda3/lib/python3.11/site-packages (from langchain) (0.0.19)\n",
      "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in /home/aiton/anaconda3/lib/python3.11/site-packages (from langchain) (2.8.4)\n",
      "Requirement already satisfied: numpy<2,>=1 in /home/aiton/anaconda3/lib/python3.11/site-packages (from langchain) (1.24.3)\n",
      "Requirement already satisfied: openapi-schema-pydantic<2.0,>=1.2 in /home/aiton/anaconda3/lib/python3.11/site-packages (from langchain) (1.2.4)\n",
      "Requirement already satisfied: pydantic<2,>=1 in /home/aiton/anaconda3/lib/python3.11/site-packages (from langchain) (1.10.12)\n",
      "Requirement already satisfied: requests<3,>=2 in /home/aiton/anaconda3/lib/python3.11/site-packages (from langchain) (2.29.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /home/aiton/anaconda3/lib/python3.11/site-packages (from langchain) (8.2.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/aiton/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (22.1.0)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /home/aiton/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.0.4)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/aiton/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /home/aiton/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/aiton/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.8.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/aiton/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/aiton/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.2.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /home/aiton/anaconda3/lib/python3.11/site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (3.20.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /home/aiton/anaconda3/lib/python3.11/site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (0.9.0)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /home/aiton/anaconda3/lib/python3.11/site-packages (from pydantic<2,>=1->langchain) (4.6.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/aiton/anaconda3/lib/python3.11/site-packages (from requests<3,>=2->langchain) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/aiton/anaconda3/lib/python3.11/site-packages (from requests<3,>=2->langchain) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/aiton/anaconda3/lib/python3.11/site-packages (from requests<3,>=2->langchain) (2023.5.7)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /home/aiton/anaconda3/lib/python3.11/site-packages (from SQLAlchemy<3,>=1.4->langchain) (2.0.1)\n",
      "Requirement already satisfied: packaging>=17.0 in /home/aiton/anaconda3/lib/python3.11/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (23.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /home/aiton/anaconda3/lib/python3.11/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (0.4.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install openai\n",
    "!pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e66e6df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = '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'\n",
    "os.environ[\"SERPAPI_API_KEY\"] = '7bf7501c0e4a586b33cf1cc0750541357e3654635d7de645e41d3b17b07ab819'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2115459b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting unstructured\n",
      "  Downloading unstructured-0.9.0-py3-none-any.whl (1.4 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m80.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0mm\n",
      "\u001b[?25hRequirement already satisfied: chardet in /home/aiton/anaconda3/lib/python3.11/site-packages (from unstructured) (4.0.0)\n",
      "Collecting filetype (from unstructured)\n",
      "  Downloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
      "Collecting python-magic (from unstructured)\n",
      "  Downloading python_magic-0.4.27-py2.py3-none-any.whl (13 kB)\n",
      "Requirement already satisfied: lxml in /home/aiton/anaconda3/lib/python3.11/site-packages (from unstructured) (4.9.1)\n",
      "Requirement already satisfied: nltk in /home/aiton/anaconda3/lib/python3.11/site-packages (from unstructured) (3.7)\n",
      "Requirement already satisfied: tabulate in /home/aiton/anaconda3/lib/python3.11/site-packages (from unstructured) (0.8.10)\n",
      "Requirement already satisfied: requests in /home/aiton/anaconda3/lib/python3.11/site-packages (from unstructured) (2.29.0)\n",
      "Requirement already satisfied: click in /home/aiton/anaconda3/lib/python3.11/site-packages (from nltk->unstructured) (8.0.4)\n",
      "Requirement already satisfied: joblib in /home/aiton/anaconda3/lib/python3.11/site-packages (from nltk->unstructured) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /home/aiton/anaconda3/lib/python3.11/site-packages (from nltk->unstructured) (2022.7.9)\n",
      "Requirement already satisfied: tqdm in /home/aiton/anaconda3/lib/python3.11/site-packages (from nltk->unstructured) (4.65.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/aiton/anaconda3/lib/python3.11/site-packages (from requests->unstructured) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/aiton/anaconda3/lib/python3.11/site-packages (from requests->unstructured) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/aiton/anaconda3/lib/python3.11/site-packages (from requests->unstructured) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/aiton/anaconda3/lib/python3.11/site-packages (from requests->unstructured) (2023.5.7)\n",
      "Installing collected packages: filetype, python-magic, unstructured\n",
      "Successfully installed filetype-1.2.0 python-magic-0.4.27 unstructured-0.9.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install unstructured"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33661abf",
   "metadata": {},
   "source": [
    "from langchain.document_loaders import UnstructuredFileLoader\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain import OpenAI\n",
    "\n",
    "# 导入文本\n",
    "loader = UnstructuredFileLoader(\"/home/aiton/Downloads/lg_test.txt\")\n",
    "# 将文本转成 Document 对象\n",
    "document = loader.load()\n",
    "print(f'documents:{len(document)}')\n",
    "\n",
    "# 初始化文本分割器\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 500,\n",
    "    chunk_overlap = 0\n",
    ")\n",
    "\n",
    "# 切分文本\n",
    "split_documents = text_splitter.split_documents(document)\n",
    "print(f'documents:{len(split_documents)}')\n",
    "\n",
    "# 加载 llm 模型\n",
    "llm = OpenAI(model_name=\"text-davinci-003\", max_tokens=1500)\n",
    "\n",
    "# 创建总结链\n",
    "chain = load_summarize_chain(llm, chain_type=\"refine\", verbose=True)\n",
    "\n",
    "# 执行总结链，（为了快速演示，只总结前5段）\n",
    "chain.run(split_documents[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ad15dc3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/aiton/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data] Error with downloaded zip file\n"
     ]
    },
    {
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource \u001b[93mpunkt\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtokenizers/punkt/PY3/english.pickle\u001b[0m\n\n  Searched in:\n    - '/home/aiton/nltk_data'\n    - '/home/aiton/anaconda3/nltk_data'\n    - '/home/aiton/anaconda3/share/nltk_data'\n    - '/home/aiton/anaconda3/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n    - ''\n**********************************************************************\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OpenAI\n\u001b[1;32m      6\u001b[0m loader \u001b[38;5;241m=\u001b[39m UnstructuredFileLoader(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/home/aiton/Downloads/lg_test.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 7\u001b[0m document \u001b[38;5;241m=\u001b[39m loader\u001b[38;5;241m.\u001b[39mload()\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdocuments:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(document)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     10\u001b[0m text_splitter \u001b[38;5;241m=\u001b[39m RecursiveCharacterTextSplitter(\n\u001b[1;32m     11\u001b[0m     chunk_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m500\u001b[39m,\n\u001b[1;32m     12\u001b[0m     chunk_overlap \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     13\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/langchain/document_loaders/unstructured.py:86\u001b[0m, in \u001b[0;36mUnstructuredBaseLoader.load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[Document]:\n\u001b[1;32m     85\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Load file.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 86\u001b[0m     elements \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_elements()\n\u001b[1;32m     87\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124melements\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     88\u001b[0m         docs: List[Document] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/langchain/document_loaders/unstructured.py:171\u001b[0m, in \u001b[0;36mUnstructuredFileLoader._get_elements\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_elements\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List:\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01munstructured\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpartition\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mauto\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m partition\n\u001b[0;32m--> 171\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m partition(filename\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile_path, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munstructured_kwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/unstructured/partition/auto.py:243\u001b[0m, in \u001b[0;36mpartition\u001b[0;34m(filename, content_type, file, file_filename, url, include_page_breaks, strategy, encoding, paragraph_grouper, headers, skip_infer_table_types, ssl_verify, ocr_languages, pdf_infer_table_structure, xml_keep_tags, data_source_metadata, **kwargs)\u001b[0m\n\u001b[1;32m    232\u001b[0m     elements \u001b[38;5;241m=\u001b[39m partition_image(\n\u001b[1;32m    233\u001b[0m         filename\u001b[38;5;241m=\u001b[39mfilename,  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m    234\u001b[0m         file\u001b[38;5;241m=\u001b[39mfile,  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    240\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    241\u001b[0m     )\n\u001b[1;32m    242\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m filetype \u001b[38;5;241m==\u001b[39m FileType\u001b[38;5;241m.\u001b[39mTXT:\n\u001b[0;32m--> 243\u001b[0m     elements \u001b[38;5;241m=\u001b[39m partition_text(\n\u001b[1;32m    244\u001b[0m         filename\u001b[38;5;241m=\u001b[39mfilename,\n\u001b[1;32m    245\u001b[0m         file\u001b[38;5;241m=\u001b[39mfile,\n\u001b[1;32m    246\u001b[0m         encoding\u001b[38;5;241m=\u001b[39mencoding,\n\u001b[1;32m    247\u001b[0m         paragraph_grouper\u001b[38;5;241m=\u001b[39mparagraph_grouper,\n\u001b[1;32m    248\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    249\u001b[0m     )\n\u001b[1;32m    250\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m filetype \u001b[38;5;241m==\u001b[39m FileType\u001b[38;5;241m.\u001b[39mRTF:\n\u001b[1;32m    251\u001b[0m     elements \u001b[38;5;241m=\u001b[39m partition_rtf(\n\u001b[1;32m    252\u001b[0m         filename\u001b[38;5;241m=\u001b[39mfilename,\n\u001b[1;32m    253\u001b[0m         file\u001b[38;5;241m=\u001b[39mfile,\n\u001b[1;32m    254\u001b[0m         include_page_breaks\u001b[38;5;241m=\u001b[39minclude_page_breaks,\n\u001b[1;32m    255\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    256\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/unstructured/documents/elements.py:222\u001b[0m, in \u001b[0;36mprocess_metadata.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    220\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[1;32m    221\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 222\u001b[0m     elements \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    223\u001b[0m     sig \u001b[38;5;241m=\u001b[39m inspect\u001b[38;5;241m.\u001b[39msignature(func)\n\u001b[1;32m    224\u001b[0m     params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args)), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/unstructured/file_utils/filetype.py:628\u001b[0m, in \u001b[0;36madd_metadata_with_filetype.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    626\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 628\u001b[0m     elements \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    629\u001b[0m     sig \u001b[38;5;241m=\u001b[39m inspect\u001b[38;5;241m.\u001b[39msignature(func)\n\u001b[1;32m    630\u001b[0m     params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args)), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/unstructured/partition/text.py:255\u001b[0m, in \u001b[0;36mpartition_text\u001b[0;34m(filename, file, text, encoding, paragraph_grouper, metadata_filename, include_metadata, max_partition, min_partition, metadata_last_modified, **kwargs)\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m min_partition \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(file_text) \u001b[38;5;241m<\u001b[39m min_partition:\n\u001b[1;32m    253\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`min_partition` cannot be larger than the length of file contents.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 255\u001b[0m file_content \u001b[38;5;241m=\u001b[39m split_by_paragraph(\n\u001b[1;32m    256\u001b[0m     file_text,\n\u001b[1;32m    257\u001b[0m     min_partition\u001b[38;5;241m=\u001b[39mmin_partition,\n\u001b[1;32m    258\u001b[0m     max_partition\u001b[38;5;241m=\u001b[39mmax_partition,\n\u001b[1;32m    259\u001b[0m )\n\u001b[1;32m    261\u001b[0m elements: List[Element] \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    262\u001b[0m metadata \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    263\u001b[0m     ElementMetadata(\n\u001b[1;32m    264\u001b[0m         filename\u001b[38;5;241m=\u001b[39mmetadata_filename \u001b[38;5;129;01mor\u001b[39;00m filename,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    268\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m ElementMetadata()\n\u001b[1;32m    269\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/unstructured/partition/text.py:51\u001b[0m, in \u001b[0;36msplit_by_paragraph\u001b[0;34m(file_text, min_partition, max_partition)\u001b[0m\n\u001b[1;32m     47\u001b[0m file_content \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m paragraph \u001b[38;5;129;01min\u001b[39;00m paragraphs:\n\u001b[1;32m     50\u001b[0m     file_content\u001b[38;5;241m.\u001b[39mextend(\n\u001b[0;32m---> 51\u001b[0m         split_content_to_fit_max(\n\u001b[1;32m     52\u001b[0m             content\u001b[38;5;241m=\u001b[39mparagraph,\n\u001b[1;32m     53\u001b[0m             max_partition\u001b[38;5;241m=\u001b[39mmax_partition,\n\u001b[1;32m     54\u001b[0m         ),\n\u001b[1;32m     55\u001b[0m     )\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m file_content\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/unstructured/partition/text.py:94\u001b[0m, in \u001b[0;36msplit_content_to_fit_max\u001b[0;34m(content, max_partition)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msplit_content_to_fit_max\u001b[39m(\n\u001b[1;32m     89\u001b[0m     content: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m     90\u001b[0m     max_partition: Optional[\u001b[38;5;28mint\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1500\u001b[39m,\n\u001b[1;32m     91\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[1;32m     92\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Splits a paragraph or section of content so that all of the elements fit into the\u001b[39;00m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;124;03m    max partition window.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 94\u001b[0m     sentences \u001b[38;5;241m=\u001b[39m sent_tokenize(content)\n\u001b[1;32m     95\u001b[0m     chunks \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     96\u001b[0m     tmp_chunk \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/unstructured/nlp/tokenize.py:30\u001b[0m, in \u001b[0;36msent_tokenize\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"A wrapper around the NLTK sentence tokenizer with LRU caching enabled.\"\"\"\u001b[39;00m\n\u001b[1;32m     29\u001b[0m _download_nltk_package_if_not_present(package_category\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtokenizers\u001b[39m\u001b[38;5;124m\"\u001b[39m, package_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpunkt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 30\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _sent_tokenize(text)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/nltk/tokenize/__init__.py:106\u001b[0m, in \u001b[0;36msent_tokenize\u001b[0;34m(text, language)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msent_tokenize\u001b[39m(text, language\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menglish\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     97\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;124;03m    Return a sentence-tokenized copy of *text*,\u001b[39;00m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;124;03m    using NLTK's recommended sentence tokenizer\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;124;03m    :param language: the model name in the Punkt corpus\u001b[39;00m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 106\u001b[0m     tokenizer \u001b[38;5;241m=\u001b[39m load(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtokenizers/punkt/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlanguage\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pickle\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    107\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tokenizer\u001b[38;5;241m.\u001b[39mtokenize(text)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/nltk/data.py:750\u001b[0m, in \u001b[0;36mload\u001b[0;34m(resource_url, format, cache, verbose, logic_parser, fstruct_reader, encoding)\u001b[0m\n\u001b[1;32m    747\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<<Loading \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresource_url\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m>>\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    749\u001b[0m \u001b[38;5;66;03m# Load the resource.\u001b[39;00m\n\u001b[0;32m--> 750\u001b[0m opened_resource \u001b[38;5;241m=\u001b[39m _open(resource_url)\n\u001b[1;32m    752\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    753\u001b[0m     resource_val \u001b[38;5;241m=\u001b[39m opened_resource\u001b[38;5;241m.\u001b[39mread()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/nltk/data.py:876\u001b[0m, in \u001b[0;36m_open\u001b[0;34m(resource_url)\u001b[0m\n\u001b[1;32m    873\u001b[0m protocol, path_ \u001b[38;5;241m=\u001b[39m split_resource_url(resource_url)\n\u001b[1;32m    875\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m protocol \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m protocol\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnltk\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 876\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m find(path_, path \u001b[38;5;241m+\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m])\u001b[38;5;241m.\u001b[39mopen()\n\u001b[1;32m    877\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m protocol\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfile\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    878\u001b[0m     \u001b[38;5;66;03m# urllib might not use mode='rb', so handle this one ourselves:\u001b[39;00m\n\u001b[1;32m    879\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m find(path_, [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m])\u001b[38;5;241m.\u001b[39mopen()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/nltk/data.py:583\u001b[0m, in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    581\u001b[0m sep \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m70\u001b[39m\n\u001b[1;32m    582\u001b[0m resource_not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mmsg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00msep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 583\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mLookupError\u001b[39;00m(resource_not_found)\n",
      "\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mpunkt\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtokenizers/punkt/PY3/english.pickle\u001b[0m\n\n  Searched in:\n    - '/home/aiton/nltk_data'\n    - '/home/aiton/anaconda3/nltk_data'\n    - '/home/aiton/anaconda3/share/nltk_data'\n    - '/home/aiton/anaconda3/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n    - ''\n**********************************************************************\n"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders import UnstructuredFileLoader\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain import OpenAI\n",
    "\n",
    "loader = UnstructuredFileLoader(\"/home/aiton/Downloads/lg_test.txt\")\n",
    "document = loader.load()\n",
    "print(f'documents:{len(document)}')\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 500,\n",
    "    chunk_overlap = 0\n",
    ")\n",
    "\n",
    "split_documents = text_splitter.split_documents(document)\n",
    "print(f'documents:{len(split_documents)}')\n",
    "\n",
    "\n",
    "llm = OpenAI(model_name=\"text-davinci-003\",max_tokens=1500)\n",
    "\n",
    "chain = load_summarize_chain(llm,chain_type=\"refine\",verbose=True)\n",
    "\n",
    "chain.run(split_documents[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea853ad6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
